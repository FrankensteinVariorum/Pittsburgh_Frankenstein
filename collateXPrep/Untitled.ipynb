{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collatex import *\n",
    "from xml.dom import pulldom\n",
    "import string\n",
    "import re\n",
    "import json\n",
    "\n",
    "regexWhitespace = re.compile(r'\\s+')\n",
    "regexNonWhitespace = re.compile(r'\\S+')\n",
    "regexEmptyTag = re.compile(r'/>$')\n",
    "regexBlankLine = re.compile(r'\\n{2,}')\n",
    "regexLeadingBlankLine = re.compile(r'^\\n')\n",
    "regexPageBreak = re.compile(r'<pb.+?/>')\n",
    "\n",
    "# Element types: xml, div, head, p, hi, pb, note, lg, l; comment()\n",
    "# Tags to ignore, with content to keep: xml\n",
    "# Structural elements: div, p, lg, l\n",
    "# Inline elements (empty) retained in normalization: pb\n",
    "# Inline elements (with content) retained in normalization: note, hi, head\n",
    "\n",
    "# GIs fall into one three classes\n",
    "ignore = ['xml']\n",
    "inlineEmpty = ['pb']\n",
    "inlineContent = ['hi']\n",
    "blockElement = ['p', 'div', 'lg', 'l', 'head', 'comment', 'note']\n",
    "\n",
    "def normalizeSpace(inText):\n",
    "    \"\"\"Replaces all whitespace spans with single space characters\"\"\"\n",
    "    if regexNonWhitespace.search(inText):\n",
    "        return regexWhitespace.sub('\\n', inText)\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def extract(input_xml):\n",
    "    \"\"\"Process entire input XML document, firing on events\"\"\"\n",
    "    # Start pulling; it continues automatically\n",
    "    doc = pulldom.parse(input_xml)\n",
    "    output = ''\n",
    "    for event, node in doc:\n",
    "        # elements to ignore: xml\n",
    "        if event == pulldom.START_ELEMENT and node.localName in ignore:\n",
    "            continue\n",
    "        # copy comments intact\n",
    "        if event == pulldom.COMMENT:\n",
    "            doc.expandNode(node)\n",
    "            output += node.toxml()\n",
    "        # empty inline elements: pb\n",
    "        elif event == pulldom.START_ELEMENT and node.localName in inlineEmpty:\n",
    "            output += node.toxml()\n",
    "        # non-empty inline elements: note, hi, head, l, lg, div, p\n",
    "        elif event == pulldom.START_ELEMENT and node.localName in inlineContent:\n",
    "            output += regexEmptyTag.sub('>', node.toxml())\n",
    "        elif event == pulldom.END_ELEMENT and node.localName in inlineContent:\n",
    "            output += '</' + node.localName + '>'\n",
    "        elif event == pulldom.START_ELEMENT and node.localName in blockElement:\n",
    "            output += '\\n<' + node.localName + '>\\n'\n",
    "        elif event == pulldom.END_ELEMENT and node.localName in blockElement:\n",
    "            output += '\\n</' + node.localName + '>'\n",
    "        elif event == pulldom.CHARACTERS:\n",
    "            output += normalizeSpace(node.data)\n",
    "    return output\n",
    "\n",
    "def normalize(inputText):\n",
    "    return regexPageBreak('',inputText)\n",
    "\n",
    "def processToken(inputText):\n",
    "    return {\"t\": inputText, \"n\": regexPageBreak.sub('',inputText)}\n",
    "\n",
    "def processWitness(inputWitness, id):\n",
    "    return {'id': id, 'tokens' : [processToken(token) for token in inputWitness]}\n",
    "\n",
    "with open('1818_Ch1.xml', 'rb') as f1818file, \\\n",
    "    open('1823_Ch1.xml', 'rb') as f1823file, \\\n",
    "    open('1831_Chs1-2.xml', 'rb') as f1831file, \\\n",
    "    open('output.txt', 'w') as outputFile:\n",
    "    f1818_tokens = regexLeadingBlankLine.sub('',regexBlankLine.sub('\\n', extract(f1831file))).split('\\n')\n",
    "    f1823_tokens = regexLeadingBlankLine.sub('',regexBlankLine.sub('\\n', extract(f1823file))).split('\\n')\n",
    "    f1831_tokens = regexLeadingBlankLine.sub('',regexBlankLine.sub('\\n', extract(f1831file))).split('\\n')\n",
    "    f1818_tokenlist = processWitness(f1818_tokens, 'f1818')\n",
    "    f1823_tokenlist = processWitness(f1823_tokens, 'f1823')\n",
    "    f1831_tokenlist = processWitness(f1831_tokens, 'f1831')\n",
    "    collation_input = {\"witnesses\": [f1818_tokenlist, f1823_tokenlist, f1831_tokenlist]}\n",
    "    table = collate(collation_input, segmentation=False, layout='vertical')\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
